# 项目总结
到目前为止，我们在中期之前完成了音乐类型分类（纯音乐与有人声的音乐），音乐节拍识别以及钢琴单音的识别。其中音乐类型分类的准确率达到90%，钢琴单音的识别准确率在95%以上。中期以前的结果在这里就不做赘述。在中期之后，我们则致力于对于复调钢琴音乐（钢琴多个键同时发声）的音符识别，以及把人声从原音频中分离出来，并且实现对人声的音调识别。在复调钢琴音乐中，我们发现复调音频特征并不是简单的由多个单音音频特征相加或者组合。因此并不能利用中期以前单个音符识别的模型，我们在做了大量文献阅读与调查后决定使用卷积神经网络作为主要模型进行音符还原。

在有人声的音乐中，主旋律多为人声的旋律，背景音乐则多为伴奏，且音轨较为复杂，不利于分析。所以在有人声的音乐中，我们选择主要分析人的声音，而不是背景音乐。而要进行人声的分离和识别则需要两个单独的神经网络，一个负责将人声从原音频中分离出来，另一个负责识别人声的音调。到目前为止，由于时间的限制，我们只完成了人声的分离的工作，并没有实现人声的音调识别。可以想象人声的识别比复调钢琴音符识别要困难许多。

![图片](https://uploader.shimo.im/f/SCaw11WJLK8S8gs6.png!thumbnail)音频处理流程图（红圈为未完成部分）

除了以上算法模型以外，我们还实现了一个网页来进行项目展示和说明，用户也可以在网页上传一段音频并且获得乐谱。以下为网页部分截图：

以上就是我们到结项为止完成的所有工作。在音乐音符识别这个总的目标下，我们已经实现了不错的结果。虽然有一些立项时的预期目标并没有完成，但是已经可以实现主要功能并且完成一定的交互。

# 未来展望
1. 功能完善

在音乐音符还原的流传中，我们并没有实现人声的音调识别。除了时间限制以外，可以预想到人声的音调识别也更加困难一些。因为相对钢琴的每个音符都有一一对应的音调，人声则有时不那么准确，也经常会出现跑调的情况。另一方面人声往往是连续的，两个不同的音符是平滑过渡的，并不会像钢琴那样出现明显的音调改变。而为了实现人声中不同音调的识别，我们可能会需要节拍的信息来帮助确认音符的变化。最后，每个人的声音音色，音调高低都不相同。这也对我们的训练数据，模型的泛化能力要求很大。想要实现人声的音调识别还需要我们很多的努力。

除了人声与钢琴音符识别外，我们还希望可以在后期的工作中继续实现其他乐器种类的音符识别，例如吉他，贝斯，长笛等音乐中常见的管弦乐器。

2. 模型优化

我们目前的模型已经可以实现复调钢琴音乐的音符识别以及人声的分离，但模型仍然有很多可以优化的地方。

对于复调钢琴音乐音符还原的模型而言，我们模型泛化能力不足。除了训练集中用的雅马哈钢琴录音外，在其他乐器的转录中效果不佳。需要使用拥有更大、更多样的音乐数据集进行训练。同时我们发现，模型在一段连续长音频转录过程中，速度极慢。需要尝试音频切割等方法或进一步改善模型运行速度（对模型进行瘦身）和优化算法，以期在长音频样本中取得更好的效果。除此之外，模型功能仍较基础，钢琴延音踏板等诸多因素还未考虑，尝试训练钢琴速率模型或将进一步提升整体效果。

对于人声分离模型而言，使用的可以说是一个图像识别网络，目前的模型太过庞大。即使是训练好的模型在运行时仍需要占用大量的CPU和内存资源，如果用户需要将应用程序下载到个人PC上运行时不太现实的，因此我们需要在保持输出结果不变的情况下，尽量地简化模型。除此之外，人声的分离效果并没有理想中的好，我们也需要改进算法，尝试使用不同的损失函数或者音频特征来进行运算，也许会达到更好的效果。

3. 提供一个可下载的应用程序

我们希望可以在进行算法和模型优化后，除了在线转录外，我们可以提供一个在PC端运行的应用程序以方便用户使用。这同时也是我们在立项初期的一个目标之一。到目前为止我们已经使用Python中的pyinstaller工具将模型打包成为一个exe文件，但生产的exe文件并不能在其他电脑环境或操作系统中运行，还需要我们做更多的工作来实现这个目标。

———已同步更新———


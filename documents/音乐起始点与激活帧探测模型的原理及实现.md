

1. **任务背景及介绍：**

在Music Information Retrieval（MIR）任务中，将一段原始音频转录为其他表征形式是非常基础的一步，对于音乐和弦识别，音乐主题分类等下游任务均具有重要意义。音乐转录任务（AMT）即旨在将源音乐转录为某种音乐特征（如MIDI）。但是，由于其固有的复调性质，钢琴音乐转录即使对人类来说也是一项难以考虑的任务。准确的音符识别因发声后能量衰减的方式而变得更加复杂，因此转录模型需要适应具有不同幅度和谐波的音符。在此，我们希望使用音乐起始点与音调识别模型能够将一段wav或mp4格式的原始音频转换为MIDI。

2. **相关工作：**

在复调钢琴音乐转录中，非负定矩阵特征（NMF）是早期的一种经典方法【8】。但是，在深度学习得到快速发展后，利用深度学习特征进行钢琴音乐转录成为了一种更为主流的方式。在【5】【6】中，受到卷积神经网络（CNN）在图像处理方面获得的巨大成功的启发，它们将卷积神经网络应用于复调钢琴音乐转录任务中。在【5】中，作者仅仅基于单一卷积神经网络就在钢琴转录任务上取得了不错的结果，证明了卷积神经网络在AMT上的作用。在【6】中，作者受到语音识别任务中的启发，使用了卷积神经网络与循环神经网络的结合，在AMT任务上取得了良好的结果。我们也将使用CNN与RNN结合的形式搭建深度神经网络，完成音乐起始点与激活帧探测模型。

3. **任务数据集：**

在Google的Magenta项目中，发布了两个用于音乐信息检索任务的数据集（Maestro Dataset & MAPS dataset）。

Maestro数据集【9】是基于国际电子钢琴竞赛的录音。在Masetro数据集中包含超过172小时由雅马哈钢琴演奏的含有成对的钢琴音频与MIDI的录音。

MAPS数据集中除含有原始音频及MIDI外，还含有单音符，和弦，以及更复杂的完整钢琴曲（包括软件模拟的合成音及雅马哈钢琴的真实录音）。

在该任务中，由于我们仅需要将WAV转换为MIDI，故我们将使用Maestro数据集完成模型的训练及评测工作。

4. **模型描述：**

在该任务中，输入为音频源文件，输出为该音频的MIDI格式。如果需要得到MIDI文件，则需要得到起始点以及被激活的帧。故我们的模型可分为起始点检测模型及激活帧检测模型。在【5】中提出了一个卷积层声学模型架构，通过卷积神经网络将输入层进行卷积堆栈使得信息得以融合流通，在我们的模型中我们同样采取了这一层。输入源音乐后，通过前文中提到的方法提取出MMF特征，作为深度神经网络的输入。将MMF特征通过卷积神经网络提取信息后，再流入一个双向递归神经网络。

起始点探测模型（figure 1），由卷积神经网络层、双向递归神经网络层、全连接层组成。

将双向循环神经网络的输出输入全连接层，经过sigmoid函数激活后，输出为88 * 帧数的预测向量。88个输出分别为该帧为88个钢琴音发生的概率。![图片](https://uploader.shimo.im/f/5SN3ubaOQEwMPd4V.png!thumbnail)

激活帧探测模型（Figure 2）与起始点探测模型有类似的网络结构。在【5】【6】中，其将每一帧作为独立，平等的输入到模型中。但是，某些帧应该更有可能为激活帧。显然，在起始点所在帧之后的帧有更大的可能为激活帧。所以我们将利用起始点检测模型检测到的起始帧作为一个额外的特征输入到激活帧检测模型中。同时，按照【7】提出的方法，仅仅将起始点检测器检测到的可能为起始点的帧，作为一段连续的激活帧开头。激活帧探测模型输入一段原始音频，提取到MMF特征后输入卷积神经网络，再输入到双向循环神经网络，最终经过全连接层，每一帧输出一个88维的预测向量，分别代表该帧可能为某个钢琴音调的激活帧。

![图片](https://uploader.shimo.im/f/DVHjjGR8o7gAJhmC.png!thumbnail)

整个模型的损失函数为起始点检测模型损失与激活帧探测模型损失函数之和。

![图片](https://uploader.shimo.im/f/MdZCo3YeFqsTEISg!thumbnail)
起始点检测模型损失函数为：

![图片](https://uploader.shimo.im/f/C0SG1axgbxgphYto!thumbnail)


T代表帧数，I为指示函数（当该帧为确实为起始点时，I的值为1），P为在帧t处音高p出现的概率，CE为交叉熵损失函数。

激活帧探测模型损失函数为：

![图片](https://uploader.shimo.im/f/PhKdV4pG1lkcuzNT!thumbnail)

T代表帧数，I为指示函数（当该帧为确实为激活帧时，I的值为1），P为在帧t处音高p出现的概率，CE为交叉熵损失函数。

除此之外，正如前文提到的那样，在起始帧之后的帧应该更有可能为激活帧，我们对于紧邻在起始帧之后的帧赋予了更高的权重。

![图片](https://uploader.shimo.im/f/iXGsB1KiqG8YoHGK!thumbnail)

t1为起始帧，t2 为起始帧之后的一段，t3为从起始帧开始连续的一段激活帧结束的帧，c为权重（这里设为5）。

5. **模型评测： **

我们使用google cloud存放数据集，并且使用云GPU训练模型。我们使用Tensorflow搭建了如上描述音乐起始帧及激活帧探测模型。输入一段测试音频，效果如下：

Input Spectrogram

![图片](https://uploader.shimo.im/f/5sZj7fsGtjsBhtVc!thumbnail)

Onset Prediction Posteriorgram

![图片](https://uploader.shimo.im/f/NGPXmmFTMf4bGoSK!thumbnail)

Estimated and Reference Transcription

![图片](https://uploader.shimo.im/f/fuj0mlnkxugIJ669!thumbnail)

1. 模型总结：

我们提出了一个复合式的音乐起始点和激活帧探测模型用于转录复调钢琴音乐。在maestro数据集中，该模型表现良好。在MIR或自动音乐生成等下游任务中，我们的模型将具有重要意义。但是模型尚有一些缺陷。例如，在开放数据集中测试时，我们发现模型泛化能力不足。除了训练集中用的雅马哈钢琴录音外，在其他乐器的转录中效果不佳。需要使用拥有更大、更多样的音乐数据集进行训练。同时我们发现，模型在一段连续长音频转录过程中，速度极慢。需要尝试音频切割等方法或进一步改善模型运行速度（对模型进行瘦身）和优化算法，以期在长音频样本中取得更好的效果。除此之外，模型功能仍较基础，钢琴延音踏板等诸多因素还未考虑，尝试训练钢琴速率模型或将进一步提升整体效果。

